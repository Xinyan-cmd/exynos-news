name: Strict Content Indexing
on:
  workflow_dispatch:
  schedule:
    - cron: '0 3 * * *'  # Daily at 3 AM UTC

jobs:
  strict-indexer:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Required for git history analysis

      - name: Install Dependencies
        run: |
          sudo apt-get -qq update
          sudo apt-get -qq install git jq
          pip3 -qq install beautifulsoup4 python-dateutil

      - name: Validate Posts
        run: |
          cat << 'EOF' > validate_posts.py
          import sys
          import os
          import subprocess
          from bs4 import BeautifulSoup
          from datetime import datetime

          POSTS_DIR = 'docs/news/current'
          DATE_FORMAT = '%Y-%m-%d'

          def get_git_date(filepath):
              result = subprocess.run(
                  ['git', 'log', '--diff-filter=A', '--format=%ad', '--date=short', '--', filepath],
                  capture_output=True, text=True
              )
              dates = result.stdout.strip().split('\n')
              return dates[-1] if dates else None

          errors = []
          for filename in os.listdir(POSTS_DIR):
              if filename == 'index.html' or not filename.endswith('.html'):
                  continue

              path = os.path.join(POSTS_DIR, filename)
              with open(path) as f:
                  soup = BeautifulSoup(f, 'html.parser')

              # Extract dates from content
              meta_date = soup.find('meta', {'name': 'date'}) or \
                          soup.find('meta', {'property': 'article:published_time'})
              visible_date = soup.find(string=lambda t: t and 'Published:' in t)
              git_date = get_git_date(path)

              # Validation logic
              try:
                  if meta_date and visible_date:
                      errors.append(f"‚ö†Ô∏è {filename}: Both meta and visible dates present")
                  elif not meta_date and not visible_date:
                      errors.append(f"‚ùå {filename}: No date found, using git date: {git_date}")
                  else:
                      date_str = meta_date['content'] if meta_date else visible_date.split(':')[-1].strip()
                      datetime.strptime(date_str, DATE_FORMAT)
              except Exception as e:
                  errors.append(f"üö´ {filename}: Invalid date ({e}), using git date: {git_date}")

          if errors:
              print("\nValidation Report:")
              for error in errors:
                  print(error)
          
          sys.exit(0 if len(errors) == 0 else 1)
          EOF
          python3 validate_posts.py

      - name: Generate Index
        run: |
          cat << 'EOF' > generate_index.py
          import os
          import json
          import subprocess
          from bs4 import BeautifulSoup
          from datetime import datetime

          def get_git_date(filepath):
              result = subprocess.run(
                  ['git', 'log', '--diff-filter=A', '--format=%ad', '--date=short', '--', filepath],
                  capture_output=True, text=True
              )
              dates = result.stdout.strip().split('\n')
              return dates[-1] if dates else None

          index = {
              "meta": {
                  "schema": "2.1-strict",
                  "generated": datetime.utcnow().isoformat(),
              },
              "posts": []
          }

          for filename in os.listdir('docs/news/current'):
              if filename == 'index.html' or not filename.endswith('.html'):
                  continue

              path = os.path.join('docs/news/current', filename)
              with open(path) as f:
                  soup = BeautifulSoup(f, 'html.parser')

              # Date extraction with fallback
              meta = soup.find('meta', {'name': 'date'}) or \
                     soup.find('meta', {'property': 'article:published_time'})
              visible = soup.find(string=lambda t: t and 'Published:' in t)
              git_date = get_git_date(path)

              date = git_date  # Default to git date
              source = 'git'
              if meta:
                  date = meta['content']
                  source = 'meta'
              elif visible:
                  date = visible.split(':')[-1].strip()
                  source = 'visible'

              # Validate date format
              try:
                  datetime.strptime(date, '%Y-%m-%d')
              except ValueError:
                  date = git_date
                  source = 'git_fallback'

              index['posts'].append({
                  "path": filename,
                  "title": soup.title.text.replace('| Exynos-News', '').strip(),
                  "date": date,
                  "source": source
              })

          index['posts'].sort(key=lambda x: x['date'], reverse=True)
          
          with open('docs/news/_index.json', 'w') as f:
              json.dump(index, f, indent=2)
          EOF
          python3 generate_index.py

      - name: Commit Changes
        run: |
          git config --global user.name "Index Guardian"
          git config --global user.email "guardian@exynos-news"
          git add docs/news/_index.json
          git commit -m "üîí Index update: $(date +'%Y-%m-%d')" || echo "No changes detected"
          git push

      - name: Final Report
        run: |
          echo "### Indexing Report" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          jq '{post_count: .posts | length, oldest_post: .posts[-1].date}' docs/news/_index.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
